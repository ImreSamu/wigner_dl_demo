{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nb_01_baby_steps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riblidezso/wigner_dl_demo/blob/master/nb_01_baby_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SlY6-tlM0Pcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Baby steps in deep learning\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tORtAyzl-2hK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load useful python packages"
      ]
    },
    {
      "metadata": {
        "id": "lSTgGCOC0XX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e86e0db6-da34-47dd-8f21-f51b876c7280"
      },
      "cell_type": "code",
      "source": [
        "# plotting and numerical basics\n",
        "%pylab inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eaRg3s1N0evC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# machine learning baselines\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBGBOvdV1UWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb323a08-1fc7-4d2f-daf5-29bae36e288b"
      },
      "cell_type": "code",
      "source": [
        "# keras deep learning framework (with tensorflow backend)\n",
        "import keras\n",
        "from keras.models import Model\n",
        "import keras.layers as kl\n",
        "import keras.regularizers as kr\n",
        "import keras.optimizers as ko"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "g3xs6GXc5UX9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST handwritten digits dataset"
      ]
    },
    {
      "metadata": {
        "id": "IOprHOQQ084n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WxYY1xqa4pXi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check some handwritten digits"
      ]
    },
    {
      "metadata": {
        "id": "QmFz_b464bvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7d852f38-7b28-4243-8c9c-e02382955e8c"
      },
      "cell_type": "code",
      "source": [
        "i = 4\n",
        "imshow(x_train[i])\n",
        "print('Label:', y_train[i] )"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQQMupSAQZcSMOhSAv8P5J4IEsW5uzQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa0c00c0a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SV94_cdD5IG6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some more info about the dataset"
      ]
    },
    {
      "metadata": {
        "id": "XWsLOlrq5Mg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "463f4b6d-6580-42d1-ded8-0934e64db7f8"
      },
      "cell_type": "code",
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wvkn-WsC_fTZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalize pixel values to 0-1 range"
      ]
    },
    {
      "metadata": {
        "id": "iUtzCbS76B9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_YFFQAb_i4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define functions for 'simple' machine learning baselines"
      ]
    },
    {
      "metadata": {
        "id": "Cxunmr078_MG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_baseline(model, x_train, y_train, N_train=60000, **kwargs):\n",
        "  \"\"\"Train a baseline sklearn model.\"\"\"\n",
        "  x_train_flat = x_train.reshape(x_train.shape[0],-1)  # flatten\n",
        "  clf = model(**kwargs)  # init machine learning model\n",
        "  clf.fit(x_train_flat[:N_train],y_train[:N_train])  # train it\n",
        "  return clf\n",
        "\n",
        "\n",
        "def test_baseline(clf, x_test, y_test):\n",
        "  \"\"\"Evaluate a baseline sklearn model.\"\"\"\n",
        "  x_test_flat = x_test.reshape(x_test.shape[0],-1)  # flatten\n",
        "  y_pred = clf.predict(x_test_flat)  # make predictions\n",
        "  acc = np.equal(y_pred, y_test).mean()  # calculate accuracy\n",
        "  print(clf.__class__.__name__, 'accuracy',acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKJ-f-BA_pUT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test logistic regression\n",
        "\n",
        "[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)"
      ]
    },
    {
      "metadata": {
        "id": "22FhFqH_5dVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ffb9d94f-0e87-4c14-e0d3-4df9e2e07993"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf = train_baseline(LogisticRegression, x_train, y_train)\n",
        "test_baseline(clf, x_test, y_test)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression accuracy 0.9201\n",
            "CPU times: user 2min 21s, sys: 95.8 ms, total: 2min 21s\n",
            "Wall time: 2min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UsVCO4fa_-S-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Random Forest\n",
        "\n",
        "[Random Forest](https://en.wikipedia.org/wiki/Random_forest)"
      ]
    },
    {
      "metadata": {
        "id": "GR4-9Pc48VWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1133b061-01dc-4a06-87e1-2cc4a95ba59f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf = train_baseline(RandomForestClassifier, x_train, y_train,\n",
        "                    n_jobs=-1, n_estimators = 300)\n",
        "test_baseline(clf, x_test, y_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier accuracy 0.971\n",
            "CPU times: user 4min 14s, sys: 448 ms, total: 4min 15s\n",
            "Wall time: 2min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cFnv2QJ_Cs7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test a simple neural network"
      ]
    },
    {
      "metadata": {
        "id": "vj5aM27zP-S2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "00317f8a-8b13-4686-dd69-8a812098e041"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf = train_baseline(MLPClassifier, x_train, y_train)\n",
        "test_baseline(clf, x_test, y_test)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLPClassifier accuracy 0.9776\n",
            "CPU times: user 2min 11s, sys: 39.3 s, total: 2min 50s\n",
            "Wall time: 1min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WdQhqG88QzYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a21a3f5a-7a3d-4a1d-fde8-42664128b860"
      },
      "cell_type": "code",
      "source": [
        "# see the params\n",
        "clf"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
              "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
              "       verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "AZlPR705Qk1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implement our own neural network for more control!"
      ]
    },
    {
      "metadata": {
        "id": "9eq1NvvxPZId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b7b2384d-7ee7-48fb-b4e1-a1f2ef2d5a28"
      },
      "cell_type": "code",
      "source": [
        "N1 = 100\n",
        "inp = kl.Input(shape=(28*28,),name='input')  # the input data tensor\n",
        "x = kl.Dense(N1, activation='relu')(inp)  # first dense layer\n",
        "x = kl.Dense(10, activation='softmax')(x)  # prediction layer\n",
        "clf = Model(inputs=inp, outputs=x)  # define the model\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "clf.summary()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cj6_7DP1R7EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b78dda42-148d-4bbc-bfa8-3ea73e35a429"
      },
      "cell_type": "code",
      "source": [
        "# Train it\n",
        "clf.fit(x_train.reshape(x_train.shape[0],-1), y_train, epochs=10,batch_size=256,\n",
        "        validation_data=(x_test.reshape(x_test.shape[0],-1), y_test))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.4828 - acc: 0.8703 - val_loss: 0.2485 - val_acc: 0.9317\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.2171 - acc: 0.9395 - val_loss: 0.1824 - val_acc: 0.9470\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.1635 - acc: 0.9539 - val_loss: 0.1457 - val_acc: 0.9582\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.1323 - acc: 0.9628 - val_loss: 0.1264 - val_acc: 0.9621\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.1109 - acc: 0.9688 - val_loss: 0.1153 - val_acc: 0.9654\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0949 - acc: 0.9734 - val_loss: 0.1058 - val_acc: 0.9684\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0828 - acc: 0.9767 - val_loss: 0.0991 - val_acc: 0.9705\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0733 - acc: 0.9798 - val_loss: 0.0959 - val_acc: 0.9700\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0650 - acc: 0.9820 - val_loss: 0.0892 - val_acc: 0.9727\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0578 - acc: 0.9841 - val_loss: 0.0863 - val_acc: 0.9742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0a3e5c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "aWVMy5zsUyJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Try a larger network? "
      ]
    },
    {
      "metadata": {
        "id": "BQuMdVS8SnOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e41107c0-3af8-4955-8e44-17e3641df2d9"
      },
      "cell_type": "code",
      "source": [
        "N1,N2 = 1024,512\n",
        "inp = kl.Input(shape=(28*28,),name='input')\n",
        "x = kl.Dense(N1, activation='relu')(inp)  # first dense layer\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Dense(N2, activation='relu')(x)  # first dense layer\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Dense(10, activation='softmax')(x)  #prediction layers\n",
        "clf = Model(inputs=inp, outputs=x)\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "clf.summary()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,333,770\n",
            "Trainable params: 1,333,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nCdVUJwrTPVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "75365f1b-d799-482e-c549-161a3a11eaf2"
      },
      "cell_type": "code",
      "source": [
        "# Train it\n",
        "clf.fit(x_train.reshape(x_train.shape[0],-1),y_train, epochs=10, batch_size=256,\n",
        "        validation_data=(x_test.reshape(x_test.shape[0],-1), y_test))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.3121 - acc: 0.9073 - val_loss: 0.1112 - val_acc: 0.9663\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1312 - acc: 0.9605 - val_loss: 0.0808 - val_acc: 0.9759\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0993 - acc: 0.9685 - val_loss: 0.0826 - val_acc: 0.9739\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0804 - acc: 0.9747 - val_loss: 0.0646 - val_acc: 0.9805\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0692 - acc: 0.9783 - val_loss: 0.0652 - val_acc: 0.9801\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0594 - acc: 0.9814 - val_loss: 0.0618 - val_acc: 0.9817\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0543 - acc: 0.9826 - val_loss: 0.0619 - val_acc: 0.9809\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0495 - acc: 0.9844 - val_loss: 0.0537 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0457 - acc: 0.9848 - val_loss: 0.0600 - val_acc: 0.9842\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0434 - acc: 0.9852 - val_loss: 0.0601 - val_acc: 0.9819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0a3e46908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "metadata": {
        "id": "0YwDpXiNVa6Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional neural networks!"
      ]
    },
    {
      "metadata": {
        "id": "yUFwkajOOsFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to create 1 ' color channel'\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIDD66cFVjXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "5e6ac44c-771b-4a66-9336-5fd4d21b2cf0"
      },
      "cell_type": "code",
      "source": [
        "N1,N2,N3 = 32,64,128\n",
        "inp = kl.Input(shape=(28,28,1),name='input')\n",
        "x = kl.Conv2D(N1, kernel_size=(3, 3), activation='relu')(inp)\n",
        "x = kl.Conv2D(N1, (3, 3), activation='relu')(x)\n",
        "x = kl.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = kl.Conv2D(N2, (3, 3), activation='relu')(x)\n",
        "x = kl.Conv2D(N2, (3, 3), activation='relu')(x)\n",
        "x = kl.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Flatten()(x)\n",
        "x = kl.Dense(N3, activation='relu')(x)  # first dense layer\n",
        "x = kl.Dropout(0.5)(x)\n",
        "x = kl.Dense(10, activation='softmax')(x)  #prediction layers\n",
        "clf = Model(inputs=inp, outputs=x)\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "clf.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 197,482\n",
            "Trainable params: 197,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e_ShxAqQWYc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "08908ed4-be33-4aa8-ceb8-32eca042adfd"
      },
      "cell_type": "code",
      "source": [
        "# Train it\n",
        "clf.fit(x_train,y_train, epochs=10, validation_split=0.1, batch_size=256,\n",
        "        validation_data = (x_test, y_test))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 142us/step - loss: 0.3722 - acc: 0.8816 - val_loss: 0.0545 - val_acc: 0.9824\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0936 - acc: 0.9719 - val_loss: 0.0352 - val_acc: 0.9877\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0660 - acc: 0.9799 - val_loss: 0.0280 - val_acc: 0.9910\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0515 - acc: 0.9841 - val_loss: 0.0269 - val_acc: 0.9914\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0448 - acc: 0.9869 - val_loss: 0.0262 - val_acc: 0.9916\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0393 - acc: 0.9882 - val_loss: 0.0260 - val_acc: 0.9911\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0249 - val_acc: 0.9920\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0190 - val_acc: 0.9940\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0276 - acc: 0.9916 - val_loss: 0.0193 - val_acc: 0.9941\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.0174 - val_acc: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0a2c734e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "metadata": {
        "id": "bxQ_PsbXYgpN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "# 97.5 or 99.4 meh? Let's see a more impressive example: CIFAR10\n",
        "\n",
        "2.5% vs 0.6% not so meh btw\n",
        "\n",
        "[CIFAR10 website](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "metadata": {
        "id": "Jy5oaMhmY8W8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8157c003-8804-4ef6-9940-ad65b244a671"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "mnist_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
        "                 'horse','ship', 'truck']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 59s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8sKRv3Eyc_C5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test yourself at home! \n",
        "\n",
        "I can do around 96%"
      ]
    },
    {
      "metadata": {
        "id": "AMr3HKuQZDPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ce0012ff-31b9-4dc6-957b-f7cdd0c03284"
      },
      "cell_type": "code",
      "source": [
        "i = 7\n",
        "imshow(x_train[i])\n",
        "plt.axis('off')\n",
        "print('Label:', mnist_classes[ int(y_train[i]) ])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AlxAIVOiAModEIcQKET4oD/AY6KLXab7NeCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f26e88d30b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KvoY-YSUdVE7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Some info"
      ]
    },
    {
      "metadata": {
        "id": "zlKtkvg6dYaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2a3f4eab-0bc0-4d53-9982-b3763d998bbf"
      },
      "cell_type": "code",
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "strh_HjpdPyG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Normalize data"
      ]
    },
    {
      "metadata": {
        "id": "7iZrVCLPcPLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWJ17ayRdf3v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Baselines\n",
        "\n",
        "Logistic regression takes forever!"
      ]
    },
    {
      "metadata": {
        "id": "2RK6D9lldhjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5f60acad-24e5-4c05-8407-9a9d3748152f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf = train_baseline(RandomForestClassifier, x_train, y_train.flatten(),\n",
        "                    n_jobs=-1, n_estimators = 100)\n",
        "test_baseline(clf, x_test, y_test.flatten())"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier accuracy 0.467\n",
            "CPU times: user 6min 44s, sys: 0 ns, total: 6min 44s\n",
            "Wall time: 3min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bFDinMXnePj4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OK, so this is much harder. Let's see neural nets!"
      ]
    },
    {
      "metadata": {
        "id": "JiemAVx2fRrg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First a simple MLP "
      ]
    },
    {
      "metadata": {
        "id": "e0yviJBxeO7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "5b860b65-b353-4edd-bbdc-1e36efe41644"
      },
      "cell_type": "code",
      "source": [
        "N1 = 200\n",
        "inp = kl.Input(shape=(32*32*3,),name='input')  # the input data tensor\n",
        "x = kl.Dense(N1, activation='relu')(inp)  # first dense layer\n",
        "x = kl.Dense(10, activation='softmax')(x)  # prediction layer\n",
        "clf = Model(inputs=inp, outputs=x)  # define the model\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "print(clf.summary())\n",
        "\n",
        "# Train it\n",
        "clf.fit(x_train.reshape(x_train.shape[0],-1), y_train, epochs=10,batch_size=256,\n",
        "        validation_data=(x_test.reshape(x_test.shape[0],-1), y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               614600    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 616,610\n",
            "Trainable params: 616,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 2s 35us/step - loss: 1.9453 - acc: 0.3062 - val_loss: 1.8307 - val_acc: 0.3483\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.7767 - acc: 0.3722 - val_loss: 1.7414 - val_acc: 0.3813\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.7088 - acc: 0.3992 - val_loss: 1.6737 - val_acc: 0.4092\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.6569 - acc: 0.4173 - val_loss: 1.6640 - val_acc: 0.4122\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.6216 - acc: 0.4302 - val_loss: 1.6001 - val_acc: 0.4364\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 31us/step - loss: 1.5909 - acc: 0.4417 - val_loss: 1.5921 - val_acc: 0.4358\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 1s 30us/step - loss: 1.5684 - acc: 0.4446 - val_loss: 1.5768 - val_acc: 0.4433\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.5465 - acc: 0.4570 - val_loss: 1.5651 - val_acc: 0.4465\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 1s 30us/step - loss: 1.5245 - acc: 0.4621 - val_loss: 1.5564 - val_acc: 0.4446\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 30us/step - loss: 1.5124 - acc: 0.4657 - val_loss: 1.5520 - val_acc: 0.4466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11b241fda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "TiSBhhQyigQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Maybe a larger one?"
      ]
    },
    {
      "metadata": {
        "id": "MDzodQKC1Kin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "1f6a2d5a-9088-4228-b246-f22afc35bee8"
      },
      "cell_type": "code",
      "source": [
        "N1,N2 = 1024,512\n",
        "inp = kl.Input(shape=(32*32*3,),name='input')\n",
        "x = kl.Dense(N1, activation='relu')(inp)  # first dense layer\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Dense(N2, activation='relu')(x)  # first dense layer\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Dense(10, activation='softmax')(x)  #prediction layers\n",
        "clf = Model(inputs=inp, outputs=x)\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "print(clf.summary())\n",
        "\n",
        "# Train it\n",
        "clf.fit(x_train.reshape(x_train.shape[0],-1), y_train, epochs=20,batch_size=256,\n",
        "        validation_data=(x_test.reshape(x_test.shape[0],-1), y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 3,676,682\n",
            "Trainable params: 3,676,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 3s 62us/step - loss: 2.0442 - acc: 0.2669 - val_loss: 1.7902 - val_acc: 0.3531\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.8089 - acc: 0.3504 - val_loss: 1.6953 - val_acc: 0.4073\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.7444 - acc: 0.3729 - val_loss: 1.6782 - val_acc: 0.4039\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.7021 - acc: 0.3858 - val_loss: 1.6128 - val_acc: 0.4201\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.6655 - acc: 0.4028 - val_loss: 1.5777 - val_acc: 0.4383\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.6445 - acc: 0.4088 - val_loss: 1.5756 - val_acc: 0.4401\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.6365 - acc: 0.4134 - val_loss: 1.5503 - val_acc: 0.4504\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.6016 - acc: 0.4234 - val_loss: 1.5328 - val_acc: 0.4580\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.6060 - acc: 0.4214 - val_loss: 1.5605 - val_acc: 0.4592\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.5911 - acc: 0.4281 - val_loss: 1.5043 - val_acc: 0.4705\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.5672 - acc: 0.4362 - val_loss: 1.4939 - val_acc: 0.4693\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.5550 - acc: 0.4421 - val_loss: 1.4840 - val_acc: 0.4804\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.5410 - acc: 0.4464 - val_loss: 1.4725 - val_acc: 0.4801\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.5345 - acc: 0.4463 - val_loss: 1.4877 - val_acc: 0.4807\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.5228 - acc: 0.4545 - val_loss: 1.4740 - val_acc: 0.4835\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.5121 - acc: 0.4571 - val_loss: 1.4550 - val_acc: 0.4846\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.5040 - acc: 0.4569 - val_loss: 1.4522 - val_acc: 0.4888\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.4975 - acc: 0.4626 - val_loss: 1.4873 - val_acc: 0.4708\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 2s 48us/step - loss: 1.4968 - acc: 0.4611 - val_loss: 1.4372 - val_acc: 0.4914\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 2s 49us/step - loss: 1.4817 - acc: 0.4671 - val_loss: 1.4286 - val_acc: 0.4943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11b15ae2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "PN0ugLCIfq5V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional, the same as before?"
      ]
    },
    {
      "metadata": {
        "id": "B7OCGeddftNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "eb2469a8-ae13-46a9-810f-837d386b4354"
      },
      "cell_type": "code",
      "source": [
        "N1,N2,N3 = 32,64,128\n",
        "inp = kl.Input(shape=(32,32,3),name='input')\n",
        "x = kl.Conv2D(N1, kernel_size=(3, 3), activation='relu')(inp)\n",
        "x = kl.Conv2D(N1, (3, 3), activation='relu')(x)\n",
        "x = kl.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = kl.Conv2D(N2, (3, 3), activation='relu')(x)\n",
        "x = kl.Conv2D(N2, (3, 3), activation='relu')(x)\n",
        "x = kl.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = kl.Dropout(0.25)(x)\n",
        "x = kl.Flatten()(x) \n",
        "x = kl.Dense(N3, activation='relu')(x)  # first dense layer\n",
        "x = kl.Dropout(0.5)(x)\n",
        "x = kl.Dense(10, activation='softmax')(x)  #prediction layers\n",
        "clf = Model(inputs=inp, outputs=x)\n",
        "clf.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
        "           metrics=['accuracy'])\n",
        "clf.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 271,786\n",
            "Trainable params: 271,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i6oN6IUEfzAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "fec5867c-3b25-44b3-a37b-a37fa6b08ff5"
      },
      "cell_type": "code",
      "source": [
        "# Train it\n",
        "clf.fit(x_train,y_train, epochs=30, validation_split=0.1, batch_size=256,\n",
        "        validation_data = (x_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 8s 168us/step - loss: 1.7983 - acc: 0.3360 - val_loss: 1.5424 - val_acc: 0.4422\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 1.4371 - acc: 0.4792 - val_loss: 1.2297 - val_acc: 0.5547\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 1.2716 - acc: 0.5477 - val_loss: 1.1403 - val_acc: 0.5921\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 1.1690 - acc: 0.5865 - val_loss: 1.0914 - val_acc: 0.6122\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 1.0780 - acc: 0.6185 - val_loss: 0.9853 - val_acc: 0.6547\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 1.0235 - acc: 0.6406 - val_loss: 0.9572 - val_acc: 0.6627\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.9662 - acc: 0.6598 - val_loss: 0.8816 - val_acc: 0.6862\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.9274 - acc: 0.6756 - val_loss: 0.8965 - val_acc: 0.6863\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.8866 - acc: 0.6885 - val_loss: 0.8374 - val_acc: 0.7029\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.8487 - acc: 0.7019 - val_loss: 0.7910 - val_acc: 0.7225\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.8209 - acc: 0.7107 - val_loss: 0.7668 - val_acc: 0.7350\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.7958 - acc: 0.7207 - val_loss: 0.7815 - val_acc: 0.7264\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 7s 147us/step - loss: 0.7633 - acc: 0.7322 - val_loss: 0.7698 - val_acc: 0.7299\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.7486 - acc: 0.7368 - val_loss: 0.7404 - val_acc: 0.7405\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.7245 - acc: 0.7463 - val_loss: 0.7529 - val_acc: 0.7371\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.7110 - acc: 0.7473 - val_loss: 0.7257 - val_acc: 0.7503\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.6992 - acc: 0.7523 - val_loss: 0.6952 - val_acc: 0.7583\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.6705 - acc: 0.7647 - val_loss: 0.6857 - val_acc: 0.7626\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.6601 - acc: 0.7663 - val_loss: 0.6866 - val_acc: 0.7658\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.6435 - acc: 0.7735 - val_loss: 0.6956 - val_acc: 0.7602\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.6275 - acc: 0.7786 - val_loss: 0.6880 - val_acc: 0.7645\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.6197 - acc: 0.7801 - val_loss: 0.6998 - val_acc: 0.7622\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.6090 - acc: 0.7850 - val_loss: 0.6795 - val_acc: 0.7698\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.6042 - acc: 0.7851 - val_loss: 0.6823 - val_acc: 0.7688\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.5869 - acc: 0.7918 - val_loss: 0.6694 - val_acc: 0.7749\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.5754 - acc: 0.7964 - val_loss: 0.6662 - val_acc: 0.7728\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 7s 143us/step - loss: 0.5625 - acc: 0.7992 - val_loss: 0.6747 - val_acc: 0.7673\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.5533 - acc: 0.8004 - val_loss: 0.6658 - val_acc: 0.7777\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.5432 - acc: 0.8063 - val_loss: 0.6749 - val_acc: 0.7718\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.5414 - acc: 0.8077 - val_loss: 0.6772 - val_acc: 0.7754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11b04026d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "fMbBdxA_gscg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# State of the art is around 97.88% [ArXiv link](https://arxiv.org/abs/1709.01507)\n"
      ]
    },
    {
      "metadata": {
        "id": "G9bF3o6VnPB6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implementation for one of the state of the art: [ResNext](https://arxiv.org/abs/1611.05431)\n",
        "\n",
        "![resnext](https://cdn-images-1.medium.com/max/1600/1*mdiQTfovOXKnqzfj727b9Q.png)\n",
        "\n",
        "\n",
        "Does not achieve the described results, tell me if you find the mistake :)"
      ]
    },
    {
      "metadata": {
        "id": "4_08chiDsmy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33915
        },
        "outputId": "3863f387-a0a7-46b9-b77c-ccb539e0e5e9"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Train resnext of cifar10.\n",
        "The implementation follows the FAIR github repo:\n",
        "https://github.com/facebookresearch/ResNeXt\n",
        "which is slightly different than the arxiv report.\n",
        "Here I use the non-preactivation blocks.\n",
        "The specfic settings (lr,batch size ) can be changed \n",
        "to follow the original values (with enough GPUs, and time).\n",
        "Author: Dezso Ribli\n",
        "\"\"\"\n",
        "\n",
        "CARDINALITY = 16\n",
        "LR = 0.0125\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_DROP = [150,225]\n",
        "N_EPOCHS = 250\n",
        "AUG = True\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras import optimizers\n",
        "import math\n",
        "\n",
        "\n",
        "def resnext(inp, resxt_block, cardinality=4):\n",
        "    \"\"\"Return resnext.\"\"\"\n",
        "    # inital conv\n",
        "    x = Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(5e-4))(inp)\n",
        "    x = Activation('relu')(BatchNormalization()(x))\n",
        "    # residual blocks\n",
        "    x = resxt_blocks(x, resxt_block, cardinality, 64, 256, 1)\n",
        "    x = resxt_blocks(x, resxt_block, cardinality, 128, 512, 2)\n",
        "    x = resxt_blocks(x, resxt_block, cardinality, 256, 1024, 2)\n",
        "    # classifier\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(10,activation='softmax')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resxt_blocks(x, resxt_block, cardinality, n_ch1, n_ch2, init_stride, \n",
        "                 n_block=3):\n",
        "    \"\"\"Perform same size residual blocks.\"\"\"\n",
        "    x_shortcut = Conv2D(n_ch2, (1, 1), strides = init_stride, \n",
        "                        padding='same', kernel_regularizer=l2(5e-4))(x)\n",
        "    x_shortcut = BatchNormalization()(x_shortcut)\n",
        "    # first block\n",
        "    x = resxt_block(x, x_shortcut, cardinality, n_ch1, n_ch2, init_stride)\n",
        "    for i in range(n_block-1):  # the other residual blocks\n",
        "        x = resxt_block(x, x, cardinality, n_ch1, n_ch2)\n",
        "    return x\n",
        "         \n",
        "\n",
        "def resxt_block_a(x, x_shortcut, cardinality, n_ch1, n_ch2, init_stride=1):\n",
        "    \"\"\"Perform a residual block.\"\"\"\n",
        "    groups=[]\n",
        "    for i in range(cardinality):\n",
        "        y = Conv2D(n_ch1, (1, 1), strides=init_stride, \n",
        "                   kernel_regularizer=l2(5e-4), padding='same')(x)\n",
        "        y = Activation('relu')(BatchNormalization()(y))\n",
        "        y = Conv2D(n_ch1, (3, 3), padding='same', \n",
        "                   kernel_regularizer=l2(5e-4),)(y)\n",
        "        y = Activation('relu')(BatchNormalization()(y))\n",
        "        y = Conv2D(n_ch2, (1, 1), padding='same', \n",
        "                   kernel_regularizer=l2(5e-4),)(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        groups.append(y)\n",
        "    x = tf.keras.layers.add(groups)\n",
        "    x = tf.keras.layers.add([x, x_shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x   \n",
        "\n",
        "\n",
        "def resxt_block_b(x, x_shortcut, cardinality, n_ch1, n_ch2, init_stride=1):\n",
        "    \"\"\"Perform a residual block.\"\"\"\n",
        "    groups=[]\n",
        "    for i in range(cardinality):\n",
        "        y = Conv2D(n_ch1, (1, 1), strides=init_stride, \n",
        "                   kernel_regularizer=l2(5e-4), padding='same')(x)\n",
        "        y = Activation('relu')(BatchNormalization()(y))\n",
        "        y = Conv2D(n_ch1, (3, 3), padding='same', \n",
        "                   kernel_regularizer=l2(5e-4),)(y)\n",
        "        y = Activation('relu')(BatchNormalization()(y))\n",
        "        groups.append(y)\n",
        "    x = tf.keras.layers.concatenate(groups)\n",
        "    x = Conv2D(n_ch2, (1, 1), padding='same', \n",
        "               kernel_regularizer=l2(5e-4),)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = tf.keras.layers.add([x, x_shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x   \n",
        "\n",
        "\n",
        "def norm(x):\n",
        "    \"\"\"Normalize images.\"\"\"\n",
        "    x = x.astype('float32')\n",
        "    x[...,0] = (x[...,0] - x[...,0].mean())/x[...,0].std()\n",
        "    x[...,1] = (x[...,1] - x[...,1].mean())/x[...,1].std()\n",
        "    x[...,2] = (x[...,2] - x[...,2].mean())/x[...,2].std()\n",
        "    return x\n",
        "\n",
        "\n",
        "def step_decay(epoch, base_lr=LR, drop=0.1, epochs_drops=EPOCHS_DROP):\n",
        "    \"\"\"Helper for step learning rate decay.\"\"\"\n",
        "    lrate = base_lr\n",
        "    for epoch_drop in epochs_drops:\n",
        "        lrate *= math.pow(drop,math.floor(epoch/epoch_drop))\n",
        "        return lrate\n",
        "\n",
        "\n",
        "\n",
        "# SGD\n",
        "sgd = optimizers.SGD(lr=LR, decay=0, momentum=0.9, nesterov=True)\n",
        "\n",
        "# resnext\n",
        "res = resnext(Input(shape=(32,32,3)), resxt_block_b, CARDINALITY)\n",
        "res.compile(loss='sparse_categorical_crossentropy',\n",
        "            optimizer=sgd, metrics=['accuracy'])\n",
        "print(res.summary())  # print summary\n",
        "\n",
        "# load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = map(norm, (x_train, x_test))  # normalize\n",
        "\n",
        "# train on generator with standard data augmentation\n",
        "gen = ImageDataGenerator(width_shift_range=0.125,\n",
        "                         height_shift_range=0.125,\n",
        "                         horizontal_flip=True)\n",
        "train_generator = gen.flow(x_train, y_train,\n",
        "                           batch_size=BATCH_SIZE)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 64)   1792        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 64)   256         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 64)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 32, 32, 64)   4160        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 64)   256         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 64)   256         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 64)   256         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 64)   256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 64)   256         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 64)   256         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 32, 32, 64)   256         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 32, 32, 64)   256         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 64)   256         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 64)   256         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 32, 32, 64)   256         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 32, 32, 64)   256         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 32, 32, 64)   256         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 32, 32, 64)   256         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 32, 32, 64)   256         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 64)   256         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 64)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 64)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 32, 32, 64)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 32, 32, 64)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 32, 32, 64)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 32, 32, 64)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 32, 32, 64)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 64)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 64)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 64)   36928       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 64)   36928       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 64)   36928       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 64)   36928       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 64)   36928       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 64)   36928       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 64)   36928       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 32, 32, 64)   36928       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 32, 32, 64)   36928       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 64)   36928       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 64)   36928       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 64)   36928       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 32, 32, 64)   36928       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 32, 32, 64)   36928       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 64)   256         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 64)   256         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 64)   256         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 64)   256         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 64)   256         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 64)   256         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 32, 32, 64)   256         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 32, 32, 64)   256         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 64)   256         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 32, 32, 64)   256         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 32, 32, 64)   256         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 32, 32, 64)   256         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 32, 32, 64)   256         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 32, 32, 64)   256         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 32, 32, 64)   256         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 64)   256         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 64)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 64)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 64)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 32, 32, 64)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 32, 32, 64)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 32, 32, 64)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 32, 32, 64)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 32, 32, 64)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 64)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 64)   0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 1024) 0           activation_101[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_117[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_121[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 activation_125[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_129[0][0]             \n",
            "                                                                 activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 32, 32, 256)  262400      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 256)  16640       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 256)  1024        conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 256)  1024        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 256)  0           batch_normalization_138[0][0]    \n",
            "                                                                 batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 32, 32, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 32, 32, 64)   16448       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 64)   256         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 64)   256         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 64)   256         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 32, 32, 64)   256         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 32, 32, 64)   256         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 32, 32, 64)   256         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 32, 32, 64)   256         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 32, 32, 64)   256         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 32, 32, 64)   256         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 32, 32, 64)   256         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 32, 32, 64)   256         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 32, 32, 64)   256         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 32, 32, 64)   256         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 32, 32, 64)   256         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 32, 32, 64)   256         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 32, 32, 64)   256         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 32, 32, 64)   0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 32, 32, 64)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 64)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 64)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 64)   0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 64)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 32, 32, 64)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 32, 32, 64)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 32, 32, 64)   0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 32, 32, 64)   0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 32, 32, 64)   0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 32, 32, 64)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 32, 32, 64)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 32, 32, 64)   0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 32, 32, 64)   0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 32, 32, 64)   0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 32, 32, 64)   36928       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 32, 32, 64)   36928       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 32, 32, 64)   36928       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 32, 32, 64)   36928       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 32, 32, 64)   36928       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 32, 32, 64)   36928       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 32, 32, 64)   36928       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 32, 32, 64)   36928       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 32, 32, 64)   36928       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 32, 32, 64)   36928       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 32, 32, 64)   36928       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 32, 32, 64)   36928       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 32, 32, 64)   36928       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 32, 32, 64)   36928       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 32, 32, 64)   36928       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 32, 32, 64)   36928       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 64)   256         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 64)   256         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 64)   256         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 32, 32, 64)   256         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 32, 32, 64)   256         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 32, 32, 64)   256         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 32, 32, 64)   256         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 32, 32, 64)   256         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 32, 32, 64)   256         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 32, 32, 64)   256         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 32, 32, 64)   256         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 32, 32, 64)   256         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 32, 32, 64)   256         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 32, 32, 64)   256         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 32, 32, 64)   256         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 32, 32, 64)   256         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 32, 32, 64)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 64)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 64)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 64)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 64)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 64)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 64)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 64)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 32, 32, 64)   0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 32, 32, 64)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 32, 32, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 32, 32, 64)   0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 32, 32, 64)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 32, 32, 64)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 32, 32, 64)   0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 32, 32, 64)   0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 1024) 0           activation_134[0][0]             \n",
            "                                                                 activation_136[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_140[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "                                                                 activation_146[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_150[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "                                                                 activation_156[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_160[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 32, 32, 256)  262400      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 32, 32, 256)  1024        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           batch_normalization_171[0][0]    \n",
            "                                                                 activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 32, 32, 64)   16448       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 32, 32, 64)   256         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 32, 32, 64)   256         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 32, 32, 64)   256         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 32, 32, 64)   256         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 32, 32, 64)   256         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 32, 32, 64)   256         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 32, 32, 64)   256         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 32, 32, 64)   256         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 32, 32, 64)   256         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 32, 32, 64)   256         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 32, 32, 64)   256         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 32, 32, 64)   256         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 32, 32, 64)   256         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 32, 32, 64)   256         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 32, 32, 64)   256         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 32, 32, 64)   256         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 32, 32, 64)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 32, 32, 64)   0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 32, 32, 64)   0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 32, 32, 64)   0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 32, 32, 64)   0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 32, 32, 64)   0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 32, 32, 64)   0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 32, 32, 64)   0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 32, 32, 64)   0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 32, 32, 64)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 32, 32, 64)   0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 32, 32, 64)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 32, 32, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 32, 32, 64)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 32, 32, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 32, 32, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 32, 32, 64)   36928       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 32, 32, 64)   36928       activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 64)   36928       activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 32, 32, 64)   36928       activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 32, 32, 64)   36928       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 32, 32, 64)   36928       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 32, 32, 64)   36928       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 32, 32, 64)   36928       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 32, 32, 64)   36928       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 32, 32, 64)   36928       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 32, 32, 64)   36928       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 32, 32, 64)   36928       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 32, 32, 64)   36928       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 32, 32, 64)   36928       activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 32, 32, 64)   36928       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 32, 32, 64)   36928       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 32, 32, 64)   256         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 32, 32, 64)   256         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 32, 32, 64)   256         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 32, 32, 64)   256         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 32, 32, 64)   256         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 32, 32, 64)   256         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 32, 32, 64)   256         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 32, 32, 64)   256         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 32, 32, 64)   256         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 32, 32, 64)   256         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 32, 32, 64)   256         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 32, 32, 64)   256         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 32, 32, 64)   256         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 32, 32, 64)   256         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 32, 32, 64)   256         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 32, 32, 64)   256         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 32, 32, 64)   0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 32, 32, 64)   0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 32, 32, 64)   0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 32, 32, 64)   0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 32, 32, 64)   0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 32, 32, 64)   0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 32, 32, 64)   0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 32, 32, 64)   0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 32, 32, 64)   0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 32, 32, 64)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 32, 32, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 32, 32, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 32, 32, 64)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 32, 32, 64)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 32, 32, 64)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 32, 32, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 1024) 0           activation_167[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 activation_171[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "                                                                 activation_175[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "                                                                 activation_179[0][0]             \n",
            "                                                                 activation_181[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "                                                                 activation_185[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "                                                                 activation_189[0][0]             \n",
            "                                                                 activation_191[0][0]             \n",
            "                                                                 activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 32, 32, 256)  262400      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 32, 32, 256)  1024        conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 256)  0           batch_normalization_204[0][0]    \n",
            "                                                                 activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 32, 32, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 16, 16, 128)  32896       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 16, 16, 128)  512         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 16, 16, 128)  512         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 16, 16, 128)  512         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 16, 16, 128)  512         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 16, 16, 128)  512         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 16, 16, 128)  512         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 16, 16, 128)  512         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 16, 16, 128)  512         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 16, 16, 128)  512         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 16, 16, 128)  512         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 16, 16, 128)  512         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 16, 16, 128)  512         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 16, 16, 128)  512         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 16, 16, 128)  512         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 16, 16, 128)  512         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 16, 16, 128)  512         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 128)  0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 128)  0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 128)  0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 128)  0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 128)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 128)  0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 16, 16, 128)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 16, 16, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 128)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 16, 16, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 16, 16, 128)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 16, 16, 128)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 16, 16, 128)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 16, 16, 128)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 16, 16, 128)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 16, 16, 128)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 128)  147584      activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 128)  147584      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 128)  147584      activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 16, 16, 128)  147584      activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 16, 16, 128)  147584      activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 16, 16, 128)  147584      activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 16, 16, 128)  147584      activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 16, 16, 128)  147584      activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 16, 16, 128)  147584      activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 16, 16, 128)  147584      activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 16, 16, 128)  147584      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 16, 16, 128)  147584      activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 16, 16, 128)  147584      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 16, 16, 128)  147584      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 16, 16, 128)  147584      activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 16, 16, 128)  147584      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 16, 16, 128)  512         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 16, 16, 128)  512         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 16, 16, 128)  512         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 16, 16, 128)  512         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 16, 16, 128)  512         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 16, 16, 128)  512         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 16, 16, 128)  512         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 16, 16, 128)  512         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 16, 16, 128)  512         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 16, 16, 128)  512         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 16, 16, 128)  512         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 16, 16, 128)  512         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 16, 16, 128)  512         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 16, 16, 128)  512         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 16, 16, 128)  512         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 16, 16, 128)  512         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 128)  0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 128)  0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 128)  0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 128)  0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 128)  0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 128)  0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 16, 16, 128)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 16, 16, 128)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 16, 16, 128)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 16, 16, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 16, 16, 128)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 16, 16, 128)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 16, 16, 128)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 16, 16, 128)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 16, 16, 128)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 16, 16, 128)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 2048) 0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_204[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "                                                                 activation_208[0][0]             \n",
            "                                                                 activation_210[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_214[0][0]             \n",
            "                                                                 activation_216[0][0]             \n",
            "                                                                 activation_218[0][0]             \n",
            "                                                                 activation_220[0][0]             \n",
            "                                                                 activation_222[0][0]             \n",
            "                                                                 activation_224[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_228[0][0]             \n",
            "                                                                 activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 16, 16, 512)  1049088     concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 512)  131584      activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 16, 16, 512)  2048        conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 16, 16, 512)  2048        conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_238[0][0]    \n",
            "                                                                 batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 16, 16, 128)  65664       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 16, 16, 128)  512         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 16, 16, 128)  512         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 16, 16, 128)  512         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 16, 16, 128)  512         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 16, 16, 128)  512         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 16, 16, 128)  512         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 16, 16, 128)  512         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 16, 16, 128)  512         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 16, 16, 128)  512         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 16, 16, 128)  512         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 16, 16, 128)  512         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 128)  512         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 16, 16, 128)  512         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 16, 16, 128)  512         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 16, 16, 128)  512         conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 16, 16, 128)  512         conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 16, 16, 128)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 16, 16, 128)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 16, 16, 128)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 16, 16, 128)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 16, 16, 128)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 16, 16, 128)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 16, 16, 128)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 16, 16, 128)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 16, 16, 128)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 16, 16, 128)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 16, 16, 128)  0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 16, 16, 128)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 16, 16, 128)  0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 16, 16, 128)  0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 16, 16, 128)  0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 16, 16, 128)  0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 16, 16, 128)  147584      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 16, 16, 128)  147584      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 16, 16, 128)  147584      activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 16, 16, 128)  147584      activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 16, 16, 128)  147584      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 16, 16, 128)  147584      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 16, 16, 128)  147584      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 16, 16, 128)  147584      activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 16, 16, 128)  147584      activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 16, 16, 128)  147584      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 128)  147584      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 16, 16, 128)  147584      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 16, 16, 128)  147584      activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 16, 16, 128)  147584      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 16, 16, 128)  147584      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 16, 16, 128)  147584      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 16, 16, 128)  512         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 16, 16, 128)  512         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 16, 16, 128)  512         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 16, 16, 128)  512         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 16, 16, 128)  512         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 16, 16, 128)  512         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 16, 16, 128)  512         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 16, 16, 128)  512         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 16, 16, 128)  512         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 16, 16, 128)  512         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 128)  512         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 16, 16, 128)  512         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 16, 16, 128)  512         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 16, 16, 128)  512         conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 16, 16, 128)  512         conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 16, 16, 128)  512         conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 16, 16, 128)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 16, 16, 128)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 16, 16, 128)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 16, 16, 128)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 16, 16, 128)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 16, 16, 128)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 16, 16, 128)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 16, 16, 128)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 16, 16, 128)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 16, 16, 128)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 16, 16, 128)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 16, 16, 128)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 16, 16, 128)  0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 16, 16, 128)  0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 16, 16, 128)  0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 16, 16, 128)  0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 2048) 0           activation_233[0][0]             \n",
            "                                                                 activation_235[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "                                                                 activation_239[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_243[0][0]             \n",
            "                                                                 activation_245[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "                                                                 activation_249[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_253[0][0]             \n",
            "                                                                 activation_255[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "                                                                 activation_259[0][0]             \n",
            "                                                                 activation_261[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 16, 16, 512)  1049088     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 16, 16, 512)  2048        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 512)  0           batch_normalization_271[0][0]    \n",
            "                                                                 activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 16, 16, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 16, 16, 128)  65664       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 16, 16, 128)  512         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 16, 16, 128)  512         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 16, 16, 128)  512         conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 16, 16, 128)  512         conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 16, 16, 128)  512         conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 16, 16, 128)  512         conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 16, 16, 128)  512         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 16, 16, 128)  512         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 16, 16, 128)  512         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 16, 16, 128)  512         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 16, 16, 128)  512         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 16, 16, 128)  512         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 16, 16, 128)  512         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 16, 16, 128)  512         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 16, 16, 128)  512         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 16, 16, 128)  512         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 16, 16, 128)  0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 16, 16, 128)  0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 16, 16, 128)  0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 16, 16, 128)  0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 16, 16, 128)  0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 16, 16, 128)  0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 16, 16, 128)  0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 16, 16, 128)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 16, 16, 128)  0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 16, 16, 128)  0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 16, 16, 128)  0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 16, 16, 128)  0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 16, 16, 128)  0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 16, 16, 128)  0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 16, 16, 128)  0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 16, 16, 128)  0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 16, 16, 128)  147584      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 16, 16, 128)  147584      activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 16, 16, 128)  147584      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 16, 16, 128)  147584      activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 16, 16, 128)  147584      activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 16, 16, 128)  147584      activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 16, 16, 128)  147584      activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 16, 16, 128)  147584      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 16, 16, 128)  147584      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 16, 16, 128)  147584      activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 16, 16, 128)  147584      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 16, 16, 128)  147584      activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 16, 16, 128)  147584      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 16, 16, 128)  147584      activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 16, 16, 128)  147584      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 16, 16, 128)  147584      activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 16, 16, 128)  512         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 16, 16, 128)  512         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 16, 16, 128)  512         conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 16, 16, 128)  512         conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 16, 16, 128)  512         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 16, 16, 128)  512         conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 16, 16, 128)  512         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 16, 16, 128)  512         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 16, 16, 128)  512         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 16, 16, 128)  512         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 16, 16, 128)  512         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 16, 16, 128)  512         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 16, 16, 128)  512         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 16, 16, 128)  512         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 16, 16, 128)  512         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 16, 16, 128)  512         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 16, 16, 128)  0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 16, 16, 128)  0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 16, 16, 128)  0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 16, 16, 128)  0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 16, 16, 128)  0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 16, 16, 128)  0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 16, 16, 128)  0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 16, 16, 128)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 16, 16, 128)  0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 16, 16, 128)  0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 16, 16, 128)  0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 16, 16, 128)  0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 16, 16, 128)  0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 16, 16, 128)  0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 16, 16, 128)  0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 16, 16, 128)  0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 2048) 0           activation_266[0][0]             \n",
            "                                                                 activation_268[0][0]             \n",
            "                                                                 activation_270[0][0]             \n",
            "                                                                 activation_272[0][0]             \n",
            "                                                                 activation_274[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "                                                                 activation_278[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "                                                                 activation_282[0][0]             \n",
            "                                                                 activation_284[0][0]             \n",
            "                                                                 activation_286[0][0]             \n",
            "                                                                 activation_288[0][0]             \n",
            "                                                                 activation_290[0][0]             \n",
            "                                                                 activation_292[0][0]             \n",
            "                                                                 activation_294[0][0]             \n",
            "                                                                 activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 16, 16, 512)  1049088     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 16, 16, 512)  2048        conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 512)  0           batch_normalization_304[0][0]    \n",
            "                                                                 activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 16, 16, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 8, 8, 256)    131328      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 8, 8, 256)    1024        conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 8, 8, 256)    1024        conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 8, 8, 256)    1024        conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 8, 8, 256)    1024        conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 8, 8, 256)    1024        conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 8, 8, 256)    1024        conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 8, 8, 256)    1024        conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 8, 8, 256)    1024        conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 8, 8, 256)    1024        conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 8, 8, 256)    1024        conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 8, 8, 256)    1024        conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 8, 8, 256)    1024        conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 8, 8, 256)    1024        conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 8, 8, 256)    1024        conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 8, 8, 256)    1024        conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 8, 8, 256)    1024        conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 8, 8, 256)    0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 8, 8, 256)    0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 8, 8, 256)    0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 8, 8, 256)    0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 8, 8, 256)    0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 8, 8, 256)    0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 8, 8, 256)    0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 8, 8, 256)    0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 8, 8, 256)    0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 8, 8, 256)    0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 8, 8, 256)    0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 8, 8, 256)    0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 8, 8, 256)    0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 8, 8, 256)    0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 8, 8, 256)    0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 8, 8, 256)    0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 8, 8, 256)    590080      activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 8, 8, 256)    590080      activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 8, 8, 256)    590080      activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 8, 8, 256)    590080      activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 8, 8, 256)    590080      activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 8, 8, 256)    590080      activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 8, 8, 256)    590080      activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 8, 8, 256)    590080      activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 8, 8, 256)    590080      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 8, 8, 256)    590080      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 8, 8, 256)    590080      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 8, 8, 256)    590080      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 8, 8, 256)    590080      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 8, 8, 256)    590080      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 8, 8, 256)    590080      activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 8, 8, 256)    590080      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 8, 8, 256)    1024        conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 8, 8, 256)    1024        conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 8, 8, 256)    1024        conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 8, 8, 256)    1024        conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 8, 8, 256)    1024        conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 8, 8, 256)    1024        conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 8, 8, 256)    1024        conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 8, 8, 256)    1024        conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 8, 8, 256)    1024        conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 8, 8, 256)    1024        conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 8, 8, 256)    1024        conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 8, 8, 256)    1024        conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 8, 8, 256)    1024        conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 8, 8, 256)    1024        conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 8, 8, 256)    1024        conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 8, 8, 256)    1024        conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 8, 8, 256)    0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 8, 8, 256)    0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 8, 8, 256)    0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 8, 8, 256)    0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 8, 8, 256)    0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 8, 8, 256)    0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 8, 8, 256)    0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 8, 8, 256)    0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 8, 8, 256)    0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 8, 8, 256)    0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 8, 8, 256)    0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 8, 8, 256)    0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 8, 8, 256)    0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 8, 8, 256)    0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 8, 8, 256)    0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 8, 8, 256)    0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 8, 8, 4096)   0           activation_299[0][0]             \n",
            "                                                                 activation_301[0][0]             \n",
            "                                                                 activation_303[0][0]             \n",
            "                                                                 activation_305[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "                                                                 activation_309[0][0]             \n",
            "                                                                 activation_311[0][0]             \n",
            "                                                                 activation_313[0][0]             \n",
            "                                                                 activation_315[0][0]             \n",
            "                                                                 activation_317[0][0]             \n",
            "                                                                 activation_319[0][0]             \n",
            "                                                                 activation_321[0][0]             \n",
            "                                                                 activation_323[0][0]             \n",
            "                                                                 activation_325[0][0]             \n",
            "                                                                 activation_327[0][0]             \n",
            "                                                                 activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 8, 8, 1024)   4195328     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 8, 8, 1024)   525312      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 8, 8, 1024)   4096        conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 8, 8, 1024)   4096        conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_338[0][0]    \n",
            "                                                                 batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 8, 8, 1024)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 8, 8, 256)    262400      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 8, 8, 256)    1024        conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 8, 8, 256)    1024        conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 8, 8, 256)    1024        conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 8, 8, 256)    1024        conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 8, 8, 256)    1024        conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 8, 8, 256)    1024        conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 8, 8, 256)    1024        conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 8, 8, 256)    1024        conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 8, 8, 256)    1024        conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 8, 8, 256)    1024        conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 8, 8, 256)    1024        conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 8, 8, 256)    1024        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 256)    1024        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 8, 8, 256)    1024        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 8, 8, 256)    1024        conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 8, 8, 256)    1024        conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 8, 8, 256)    0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 8, 8, 256)    0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 8, 8, 256)    0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 8, 8, 256)    0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 8, 8, 256)    0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 8, 8, 256)    0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 8, 8, 256)    0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 8, 8, 256)    0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 8, 8, 256)    0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 8, 8, 256)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 8, 8, 256)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 8, 8, 256)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 8, 8, 256)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 8, 8, 256)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 8, 8, 256)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 8, 8, 256)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 8, 8, 256)    590080      activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 8, 8, 256)    590080      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 8, 8, 256)    590080      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 8, 8, 256)    590080      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 8, 8, 256)    590080      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 8, 8, 256)    590080      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 8, 8, 256)    590080      activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 8, 8, 256)    590080      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 8, 8, 256)    590080      activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 256)    590080      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 8, 8, 256)    590080      activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 8, 8, 256)    590080      activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 8, 8, 256)    590080      activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 8, 8, 256)    590080      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 8, 8, 256)    590080      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 8, 8, 256)    590080      activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 8, 8, 256)    1024        conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 8, 8, 256)    1024        conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 8, 8, 256)    1024        conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 8, 8, 256)    1024        conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 8, 8, 256)    1024        conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 8, 8, 256)    1024        conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 8, 8, 256)    1024        conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 8, 8, 256)    1024        conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 8, 8, 256)    1024        conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 8, 8, 256)    1024        conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 8, 8, 256)    1024        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 8, 8, 256)    1024        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 256)    1024        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 8, 8, 256)    1024        conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 8, 8, 256)    1024        conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 8, 8, 256)    1024        conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 8, 8, 256)    0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 8, 8, 256)    0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 8, 8, 256)    0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 8, 8, 256)    0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 8, 8, 256)    0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 8, 8, 256)    0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 8, 8, 256)    0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 8, 8, 256)    0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 8, 8, 256)    0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 8, 8, 256)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 8, 8, 256)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 8, 8, 256)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 8, 8, 256)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 8, 8, 256)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 8, 8, 256)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 8, 8, 256)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 8, 8, 4096)   0           activation_332[0][0]             \n",
            "                                                                 activation_334[0][0]             \n",
            "                                                                 activation_336[0][0]             \n",
            "                                                                 activation_338[0][0]             \n",
            "                                                                 activation_340[0][0]             \n",
            "                                                                 activation_342[0][0]             \n",
            "                                                                 activation_344[0][0]             \n",
            "                                                                 activation_346[0][0]             \n",
            "                                                                 activation_348[0][0]             \n",
            "                                                                 activation_350[0][0]             \n",
            "                                                                 activation_352[0][0]             \n",
            "                                                                 activation_354[0][0]             \n",
            "                                                                 activation_356[0][0]             \n",
            "                                                                 activation_358[0][0]             \n",
            "                                                                 activation_360[0][0]             \n",
            "                                                                 activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 8, 8, 1024)   4195328     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 8, 8, 1024)   4096        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_371[0][0]    \n",
            "                                                                 activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 8, 8, 256)    262400      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 8, 8, 256)    1024        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 8, 8, 256)    1024        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 8, 8, 256)    1024        conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 8, 8, 256)    1024        conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 8, 8, 256)    1024        conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 8, 8, 256)    1024        conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 8, 8, 256)    1024        conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 8, 8, 256)    1024        conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 8, 8, 256)    1024        conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 8, 8, 256)    1024        conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 8, 8, 256)    1024        conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 8, 8, 256)    1024        conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 8, 8, 256)    1024        conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 8, 8, 256)    1024        conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 8, 8, 256)    1024        conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 8, 8, 256)    1024        conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 256)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 8, 8, 256)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 8, 8, 256)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 8, 8, 256)    0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 8, 8, 256)    0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 8, 8, 256)    0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 8, 8, 256)    0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 8, 8, 256)    0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 8, 8, 256)    0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 8, 8, 256)    0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 8, 8, 256)    0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 8, 8, 256)    0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 8, 8, 256)    0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 8, 8, 256)    0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 8, 8, 256)    0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 8, 8, 256)    0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 8, 8, 256)    590080      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 8, 8, 256)    590080      activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 8, 8, 256)    590080      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 8, 8, 256)    590080      activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 8, 8, 256)    590080      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 8, 8, 256)    590080      activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 8, 8, 256)    590080      activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 8, 8, 256)    590080      activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 8, 8, 256)    590080      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 8, 8, 256)    590080      activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 8, 8, 256)    590080      activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 8, 8, 256)    590080      activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 8, 8, 256)    590080      activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 8, 8, 256)    590080      activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 8, 8, 256)    590080      activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 8, 8, 256)    590080      activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 8, 8, 256)    1024        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 8, 8, 256)    1024        conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 8, 8, 256)    1024        conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 8, 8, 256)    1024        conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 8, 8, 256)    1024        conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 8, 8, 256)    1024        conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 8, 8, 256)    1024        conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 8, 8, 256)    1024        conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 8, 8, 256)    1024        conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 8, 8, 256)    1024        conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 8, 8, 256)    1024        conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 8, 8, 256)    1024        conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 8, 8, 256)    1024        conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 8, 8, 256)    1024        conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 8, 8, 256)    1024        conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 8, 8, 256)    1024        conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 8, 8, 256)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 8, 8, 256)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 8, 8, 256)    0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 8, 8, 256)    0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 8, 8, 256)    0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 8, 8, 256)    0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 8, 8, 256)    0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 8, 8, 256)    0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 8, 8, 256)    0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 8, 8, 256)    0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 8, 8, 256)    0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 8, 8, 256)    0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 8, 8, 256)    0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 8, 8, 256)    0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 8, 8, 256)    0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 8, 8, 256)    0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 4096)   0           activation_365[0][0]             \n",
            "                                                                 activation_367[0][0]             \n",
            "                                                                 activation_369[0][0]             \n",
            "                                                                 activation_371[0][0]             \n",
            "                                                                 activation_373[0][0]             \n",
            "                                                                 activation_375[0][0]             \n",
            "                                                                 activation_377[0][0]             \n",
            "                                                                 activation_379[0][0]             \n",
            "                                                                 activation_381[0][0]             \n",
            "                                                                 activation_383[0][0]             \n",
            "                                                                 activation_385[0][0]             \n",
            "                                                                 activation_387[0][0]             \n",
            "                                                                 activation_389[0][0]             \n",
            "                                                                 activation_391[0][0]             \n",
            "                                                                 activation_393[0][0]             \n",
            "                                                                 activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 8, 8, 1024)   4195328     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 8, 8, 1024)   4096        conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_404[0][0]    \n",
            "                                                                 activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           10250       global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 68,305,930\n",
            "Trainable params: 68,205,450\n",
            "Non-trainable params: 100,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5RS49c5TmhOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "8de59c2f-a258-41d2-ee4d-70463a2be82b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    res,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    train_gen(1024),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(x_test, y_test),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.64.207.178:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8065862604663355995)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7057174356852335249)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 12983671754582972407)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14956557699162281848)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9481520361037722495)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14255415431813095753)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1860218609485395577)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14114348195303422956)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17466879453675450109)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1989777114742668404)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15196037354435303957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 16748414575758735431)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.012500000186264515, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.012500000186264515, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': True}\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name='input_4_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='dense_target_50')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_4\n",
            "INFO:tensorflow:Started compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ksW526crWCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}